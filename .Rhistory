TRUE ~ NA_real_
)
) %>%
filter(!is.na(A008)) %>%
group_by(S020) %>%  # Group by year (S020)
summarise(
mean_life_satisfaction = mean(A170, na.rm = TRUE),
median_life_satisfaction = median(A170, na.rm = TRUE),
mean_happiness = mean(A008, na.rm = TRUE),
median_happiness = median(A008, na.rm = TRUE),
n = n()  # Count of observations per year
) %>%
ungroup()
# Ensure S020 is numeric
swb_us <- swb_us %>%
mutate(S020 = as.numeric(as.character(S020)))
# Ensure S020 is numeric
swb_us <- swb_us %>%
mutate(S020 = as.numeric(as.character(S020)))
#save dataset so don't have to load ivs from scratch each time
write_rds(swb_us, "./data/int_val_surv/swb_us.rds")
#load US SWB data
swb_us <- read_rds("./data/int_val_surv/swb_us.rds")
View(ivs)
View(swb_us)
# Function to create plot with connected points and best fit line
create_plot <- function(data, y_var, title, y_label) {
ggplot(data, aes(x = S020, y = !!sym(y_var))) +
geom_line() +  # Connect points with a line
geom_point() +  # Add points
geom_smooth(method = "lm", se = FALSE, color = "red", linetype = "dashed") +  # Add best fit line
theme_minimal() +
labs(title = title,
x = "Year",
y = y_label) +
scale_x_continuous(breaks = unique(data$S020))
}
# Create plots
plot_satisfaction <- create_plot(swb_us, "mean_life_satisfaction",
"Mean Life Satisfaction in the US Over Time",
"Mean Life Satisfaction")
plot_happiness <- create_plot(swb_us, "mean_happiness",
"Mean Happiness in the US Over Time",
"Mean Happiness")
# Display the plots
print(plot_satisfaction)
print(plot_happiness)
#display them side by side
grid.arrange(plot_satisfaction, plot_happiness, ncol = 2)
# If you want to save the plots, you can use ggsave:
# ggsave("life_satisfaction_plot.png", plot_satisfaction, width = 10, height = 6)
# ggsave("happiness_plot.png", plot_happiness, width = 10, height = 6)
#swb_us as it is, summarised, in latex format:
kable(swb_us, format = "latex")
############################# EXTRAPOLATION
# Create linear models
lm_satisfaction <- lm(mean_life_satisfaction ~ S020, data = swb_us)
lm_happiness <- lm(mean_happiness ~ S020, data = swb_us)
# Create a data frame with all years from 1970 to 2024
all_years <- data.frame(S020 = 1970:2024)
# Predict values for all years
predictions <- all_years %>%
mutate(
mean_life_satisfaction = predict(lm_satisfaction, newdata = .),
mean_happiness = predict(lm_happiness, newdata = .)
)
# Combine predictions with actual data, preferring actual data where available
final_table <- predictions %>%
left_join(swb_us, by = "S020") %>%
mutate(
mean_life_satisfaction = coalesce(mean_life_satisfaction.y, mean_life_satisfaction.x),
mean_happiness = coalesce(mean_happiness.y, mean_happiness.x)
) %>%
select(S020, mean_life_satisfaction, mean_happiness)
View(final_table)
names(final_table)
View(final_table)
final_table <- predictions %>%
left_join(swb_us, by = "S020") %>%
mutate(
mean_life_satisfaction = coalesce(mean_life_satisfaction.y, mean_life_satisfaction.x),
mean_happiness = coalesce(mean_happiness.y, mean_happiness.x)
) %>%
select(S020, mean_life_satisfaction, mean_happiness) %>%
#rename S020 column to Time
rename(S020 = Time)
final_table <- predictions %>%
left_join(swb_us, by = "S020") %>%
mutate(
mean_life_satisfaction = coalesce(mean_life_satisfaction.y, mean_life_satisfaction.x),
mean_happiness = coalesce(mean_happiness.y, mean_happiness.x)
) %>%
select(S020, mean_life_satisfaction, mean_happiness) %>%
#rename S020 column to Time
rename(Time = S020)
########### POP DATA
#load pop data
#un_dat <- read_excel("./data/un/WPP2024_POP_F01_1_POPULATION_SINGLE_AGE_BOTH_SEXES.xlsx") #parsing issues. world_bank data also had parsing issues
un_dat <- read_csv("./data/un/WPP2024_Population1JanuaryBySingleAgeSex_Medium_1950-2023.csv.gz")
View(un_f)
#save to avoid having to load un_dat again
write_rds(un_7023, "./data/un/un_7023.rds")
#keep 1970 to 2023
un_7023 <- filter(un_f, Time >= 1970)
#save to avoid having to load un_dat again
write_rds(un_7023, "./data/un/un_7023.rds")
View(un_7023)
# Create a data frame with all years from 1970 to 2024
all_years <- data.frame(S020 = 1970:2023)
# Predict values for all years
predictions <- all_years %>%
mutate(
mean_life_satisfaction = predict(lm_satisfaction, newdata = .),
mean_happiness = predict(lm_happiness, newdata = .)
)
# Combine predictions with actual data, preferring actual data where available
final_table <- predictions %>%
left_join(swb_us, by = "S020") %>%
mutate(
mean_life_satisfaction = coalesce(mean_life_satisfaction.y, mean_life_satisfaction.x),
mean_happiness = coalesce(mean_happiness.y, mean_happiness.x)
) %>%
select(S020, mean_life_satisfaction, mean_happiness) %>%
#rename S020 column to Time
rename(Time = S020)
#final table now has three columns: Time, mean_life_satisfaction, and mean_happiness
#merge un_7023 and final_table
na_pop_us_swb <- merge(final_table, un_7023, by = "Time", all = TRUE)
View(na_pop_us_swb)
na_pop_us_swb <- merge(final_table, un_7023, by = "Time", all = TRUE) %>%
#multiply PopTot by a thousand
mutate(PopTot = PopTot*1000)
View(ivs)
names(ivs)
unique(ivs$A008)
na_pop_us_swb <- merge(final_table, un_7023, by = "Time", all = TRUE) %>%
#multiply PopTot by a thousand to it's now in individuals not thousands of individuals
mutate(PopTot = PopTot*1000,
LSTot = PopTot*mean_life_satisfaction)
#calculate number of utils
##set wd
setwd("AdamCSmithCWS-Estimating_Change_in_NorthAmerican_Birds-a78d595")
#### jags function for SOCB model
library(ggplot2)
library(ggrepel)
library(ggforce)
library(rjags)
library(jagsUI)
library(stringr)
library(MCMCvis)
library(mgcv)
ind = "index"
lci = "lci"
uci = "uci"
year = "year"
base.yr = 1970
popsource = "Pop.source"
set.seed(2019)
popest = read.csv("Rosenberg et al species list - Copy.csv",
stringsAsFactors = F)
popest$popse = ((popest$popestuci-popest$popestlci)/(1.96*2))
indicesraw = read.csv("Rosenberg et al annual indices of abundance.csv",
stringsAsFactors = F)
indicesraw = indicesraw[order(indicesraw$species,indicesraw$year),]
# ###################### GAM smoothing of indices
sps = popest$species
for(ss in sps){
wss = which(indicesraw$species == ss)
tmp = indicesraw[wss,]
fyr = unique(tmp$firstyear)
lyr = unique(tmp$lastyear)
torep = which(indicesraw$species == ss & (indicesraw$year >= fyr & indicesraw$year <= lyr))
if(any(!is.na(tmp$lci.raw))){
wprec = T
}else{
wprec = F
}
tmpd = tmp[which(!is.na(tmp$index.raw)),]
nknots = min(c(11,max(floor(nrow(tmpd)/3),3)))
if(ss %in% c("Cackling Goose","Greater White???fronted Goose")){nknots = 3}
form = as.formula(paste("lindex","~",
"s(year,k =",nknots,")"))
ncounts = nrow(tmpd)
###### building the GAM basis function
# gam basis functions created using function jagam from mgcv package
yminy = min(tmpd$year,na.rm = T)
ymaxy = max(tmpd$year,na.rm = T)
yearvec = tmpd$year-(yminy-1)
yrs = seq(yminy,ymaxy,by = 1)
nyears = length(yrs)
ymin = min(yearvec)
ymax = max(yearvec)
tmpd$lindex = log(tmpd$index.raw)
lindex = tmpd$lindex
preddat = data.frame(lindex = 1,
year = yrs)
if(wprec){
### if true then jags model runs
#### setting of the number of knots
preci = 1/(((log(tmpd[,"uci.raw"])-log(tmpd[,"lci.raw"]))/(1.96*2))^2)
gamprep = jagam(formula = form,
data = tmpd,
file = "tempgam.txt",
centred = T)
gamprep.pred = jagam(formula = form,
data = preddat,
file = "tempgampred.txt",
centred = T)
dat = list(X = gamprep$jags.data$X,
S1 = gamprep$jags.data$S1,
ncounts = nrow(tmpd),
lindex = lindex,
nknots = nknots,
preci = preci,
X.pred = gamprep.pred$jags.data$X,
zero = gamprep$jags.data$zero)
mg <- jags.model(data = dat,
file = paste0("GAM model smoothing indices jagam.txt"),
n.chains = 3)
adaptest <- adapt(object = mg,
n.iter = 10)
while(adaptest == F){
adaptest <- adapt(object = mg,
n.iter = 1000)
}
nburn = 10000
mgo = coda.samples(mg,
c("ind.pred"
#"rho"
#"mu",
#"b"
),
n.iter = 10000,
n.burnin = nburn,
thin = 10)
mgosum = summary(mgo)
predg = mgosum$quantiles
predgs = mgosum$statistics
indicesraw[torep,"index"] <- exp(predg[grep(row.names(predg),pattern = "ind.pred"),"50%"])
indicesraw[torep,"lci"] <- exp(predg[grep(row.names(predg),pattern = "ind.pred"),"2.5%"])
indicesraw[torep,"uci"] <- exp(predg[grep(row.names(predg),pattern = "ind.pred"),"97.5%"])
}else{ ### else if wprec
m1 = gam(formula = form,
data = tmpd)
pred = predict(m1,newdata = preddat,
type = "link",
se.fit = T)
indicesraw[torep,"index"] <- exp(pred$fit)
indicesraw[torep,"lci"] <- exp(pred$fit-(1.96*pred$se.fit))
indicesraw[torep,"uci"] <- exp(pred$fit+(1.96*pred$se.fit))
} ### end if wprec
}
save(indicesraw,file = "post GAM indices.RDATA")
######################### end GAM smoothing of annual indices
indices = indicesraw
yrs = sort(unique(indices$year))
indices[,"se"] <- ((indices[,uci]-indices[,lci])/(1.96*2))
indices <- indices[order(indices$firstyear,indices$species,indices$year),]
splist <- unique(indices[,c("species","firstyear","lastyear")])
splist3 = merge(splist,popest,by.x = "species",by.y = "species")
splist3$spfactor <- factor(splist3$species,
levels = splist3$species,
ordered = T)
splist3$spfact <- as.integer(splist3$spfactor)
indices$spfactor = factor(indices$species,
levels = splist3$species,
ordered = T)
splist = splist3
base.i <- rep(NA, length = length(unique(indices$species)))
names(base.i) <- unique(indices$species)
base.se.sp <- rep(NA, length = length(unique(indices$species)))
names(base.se.sp) <- unique(indices$species)
se = "se"
for (sn in 1:nrow(splist)) {
s = as.character(splist[sn,"species"])
r <- which(indices[,"species"] == s)
rmpre = which(indices[,"species"] == s &
is.na(indices[,ind]) &
indices[,"year"] < splist[sn,"firstyear"])
rmpost = which(indices[,"species"] == s &
is.na(indices[,"se"]) &
indices[,"year"] > splist[sn,"lastyear"])
base.s <- indices[which(indices$species == s & indices$year == base.yr),ind] #stores the base index value
base.se <- indices[which(indices$species == s & indices$year == base.yr),se] #stores the base se value
if(is.na(base.s)){
byr <- min(indices[which(indices$species == s & !is.na(indices[,ind])),"year"],na.rm = T)
base.s <- indices[which(indices$species == s & indices$year == byr),ind] #stores the base index value
base.se <- indices[which(indices$species == s & indices$year == byr),se] #stores the base se value
}
for (y in r) {
indices[y,"index.s"] <- (indices[y,ind])/base.s # standardized index WRT base year
indices[y,"cvar.s"] <- (((indices[y,se]^2)/(indices[y,ind]^2))+((base.se^2)/(base.s^2)))
indices[y,"logthetahat"] <- log(indices[y,"index.s"])
indices[y,"prec.logthetahat"] <- 1/log(1+(indices[y,"cvar.s"]))
}
print(s)
}
indices = merge(indices,splist[,c("species","spfactor","spfact")],by = "species")
indices$year_i = (indices$year - base.yr)+1
indices = indices[order(indices$spfact,indices$year_i),]
splist = splist[order(splist$spfact),]
nspecies <- nrow(splist)
nyears = max(indices$year_i)
splist$g1 = as.integer(factor(splist$Winter.Biome))
splist$g2 = as.integer(factor(splist$Breeding.Biome))
grps = as.matrix(splist[,c("g1","g2")])
ngroups1 = max(grps[,1])
ngroups2 = max(grps[,2])
ident = function(x){
return(x)
}
logthetahat <- as.matrix(tapply(indices[,"logthetahat"],indices[,c("spfact","year_i")],ident))
prec.logthetahat <- as.matrix(tapply(indices[,"prec.logthetahat"],indices[,c("spfact","year_i")],ident))
ne = splist$popest #population estimate
tau.ne = 1/splist$popse^2 #precision of population estimate
#
#
yest = (splist$year_est1-base.yr)+1 # first year over which species population should be averaged
yavg = 1+(splist$year_est2-splist$year_est1) ## number of years over which to average the species population estimate
##### species group indexing
subgrps = unique(grps)
subgrps = subgrps[order(subgrps[,1],subgrps[,2]),]
nsubgrps = table(subgrps[,1])
subgrpsl = matrix(NA,ncol = ngroups1,nrow = max(nsubgrps))
nsppsubbiomesmat = table(grps[,1],grps[,2])
spsubgrpmat = array(NA,dim = c(ngroups1,ngroups2,max(nsppsubbiomesmat)))
for(i in 1:ngroups1){
subs = subgrps[which(subgrps[,1] == i),2]
subgrpsl[1:nsubgrps[i],i] = subs
for(j in subs){
spsubgrpmat[i,j,1:nsppsubbiomesmat[i,j]] = which(grps[,1] == i & grps[,2] == j)
}
}#i
#### breeding biome indexing
nsppbiomes = table(grps[,2])
spinbiomes = matrix(NA,nrow = max(nsppbiomes),ncol = max(ngroups2))
for(g in 1:ngroups2){
spinbiomes[1:nsppbiomes[g],g] <- which(grps[,2] == g)
}
### wintering biome indexing
nsppwinters = table(grps[,1])
spinwinters = matrix(NA,nrow = max(nsppwinters),ncol = max(ngroups1))
for(g in 1:ngroups1){
spinwinters[1:nsppwinters[g],g] <- which(grps[,1] == g)
}
### indexing for family summaries
splist$famfact = (factor(splist$Family))
splist$famfactn = as.integer(factor(splist$Family))
nsppfams = table(splist$famfact)
spinfams = matrix(NA,nrow = max(nsppfams),ncol = length(nsppfams))
for(f in 1:length(nsppfams)){
fn = names(nsppfams)[f]
spinfams[1:nsppfams[f],f] <- which(splist$Family == fn)
}
nfams = length(nsppfams)
fams = unique(splist[,c("Family","famfact","famfactn")])
fams = fams[order(fams$famfactn),]
#indexing for bird.group summaries
splist$birdgroupfact = (factor(splist$bird.group))
splist$birdgroupfactn = as.integer(factor(splist$bird.group))
nsppbirdgroups = table(splist$birdgroupfact)
spinbirdgroups = matrix(NA,nrow = max(nsppbirdgroups),ncol = length(nsppbirdgroups))
for(f in 1:length(nsppbirdgroups)){
fn = names(nsppbirdgroups)[f]
spinbirdgroups[1:nsppbirdgroups[f],f] <- which(splist$bird.group == fn)
}
nbirdgroups = length(nsppbirdgroups)
birdgroups = unique(splist[,c("bird.group","birdgroupfact","birdgroupfactn")])
birdgroups = birdgroups[order(birdgroups$birdgroupfactn),]
#indexing for migration summaries
splist$migratefact = (factor(splist$Migrate))
splist$migratefactn = as.integer(factor(splist$Migrate))
nsppmigrates = table(splist$migratefact)
spinmigrates = matrix(NA,nrow = max(nsppmigrates),ncol = length(nsppmigrates))
for(f in 1:length(nsppmigrates)){
fn = names(nsppmigrates)[f]
spinmigrates[1:nsppmigrates[f],f] <- which(splist$Migrate == fn)
}
nmigrates = length(nsppmigrates)
migrates = unique(splist[,c("Migrate","migratefact","migratefactn")])
migrates = migrates[order(migrates$migratefactn),]
#indexing for ai summaries
splist$aifact = (factor(splist$AI))
splist$aifactn = as.integer(factor(splist$AI))
nsppais = table(splist$aifact)
spinais = matrix(NA,nrow = max(nsppais),ncol = length(nsppais))
for(f in 1:length(nsppais)){
fn = names(nsppais)[f]
spinais[1:nsppais[f],f] <- which(splist$AI == fn)
}
nais = length(nsppais)
ais = unique(splist[,c("AI","aifact","aifactn")])
ais = ais[order(ais$aifactn),]
#indexing for native summaries
splist$nativefact = (factor(splist$native))
splist$nativefactn = as.integer(factor(splist$native))
nsppnatives = table(splist$nativefact)
spinnatives = matrix(NA,nrow = max(nsppnatives),ncol = length(nsppnatives))
for(f in 1:length(nsppnatives)){
fn = names(nsppnatives)[f]
spinnatives[1:nsppnatives[f],f] <- which(splist$native == fn)
}
nnatives = length(nsppnatives)
natives = unique(splist[,c("native","nativefact","nativefactn")])
natives = natives[order(natives$nativefactn),]
#imputing the missing data with assumptions of no-change from most recent year with data and gradually decreasing precision
wspecieslate = as.integer(splist[which(splist$firstyear > 1970),"spfact"])
yearswo1late = rep(1,nspecies)
yearswo2late = (splist[,"firstyear"])-1970
wspeciesearly = as.integer(splist[which(splist$lastyear < 2017),"spfact"])
yearswo1early = (splist[,"lastyear"]+1)-1969
yearswo2early = rep(nyears,nspecies)
yearsw1 = (splist[,"firstyear"])-1969
yearsw2 = (splist[,"lastyear"])-1969
prec.powdrop = 2 #exponential function for decreasing precision with years (i.e., precision decreases with square of the years since real data)
for( s in wspecieslate) { # wspecieslate = vector of species that don't have data in year-1
for(y in yearswo1late[s]:yearswo2late[s]){
logthetahat[s,y] <- logthetahat[s,yearsw1[s]]
prec.logthetahat[s,y] <- prec.logthetahat[s,yearsw1[s]]/((yearsw1[s]-y)^prec.powdrop)#
}}
### imputing missing data for species without data at the end of the time series
## currently assumes that the precision decreases with the square of the number of years since the last data
for( s in wspeciesearly) { # wspecieslate = vector of species that don't have data in year-1
for(y in yearswo1early[s]:yearswo2early[s]){
logthetahat[s,y] <- logthetahat[s,yearsw2[s]]
prec.logthetahat[s,y] <- prec.logthetahat[s,yearsw2[s]]/((y-yearsw2[s])^prec.powdrop)#
}}
data.jags = list(nspecies = nspecies,
nyears = nyears,
logthetahat = logthetahat,
prec.logthetahat = prec.logthetahat,
ne = ne,
tau.ne = tau.ne,
yest = yest,
ngroups1 = ngroups1,
ngroups2 = ngroups2,
grps = grps,
yavg = yavg,
spinbiomes = spinbiomes,
nsppbiomes = nsppbiomes,
spinfams = spinfams,
nsppfams = nsppfams,
nfams = nfams,
spinbirdgroups = spinbirdgroups,
nsppbirdgroups = nsppbirdgroups,
nbirdgroups = nbirdgroups,
spinmigrates = spinmigrates,
nsppmigrates = nsppmigrates,
nmigrates = nmigrates,
spinais = spinais,
nsppais = nsppais,
nais = nais,
spinwinters = spinwinters,
nsppwinters = nsppwinters,
spinnatives = spinnatives,
nsppnatives = nsppnatives,
nnatives = nnatives,
subgrpsl = subgrpsl,
nsubgrps = nsubgrps,
nsppsubbiomesmat = nsppsubbiomesmat,
spsubgrpmat = spsubgrpmat)
params = c("expmu1",
#"expm2",
"expmu2",
"Psi",
"tau",
"NEst",
"Nsum",
"N",
"Nlost",
"Nalost",
"Nlost.S",
"Nlost.fam",
"Nlost.biome",
"Nalost.fam",
"Nlost.migrate",
"Nalost.migrate",
"plost.migrate",
"Nlost.birdgroup",
"Nalost.birdgroup",
"plost.birdgroup",
"Nlost.ai",
"Nalost.ai",
"plost.ai",
"plost.native",
"Nlost.native",
"Nalost.native",
"plost.winter",
"Nlost.winter",
"Nalost.winter",
"Nalost.biome",
"plost.fam",
"plost.biome",
"plost",
"Nsum.subgrp")
mod = "Rosenberg et al model.txt"
adaptSteps = 500              # Number of steps to "tune" the samplers.
burnInSteps = 30000            # Number of steps to "burn-in" the samplers.
nChains = 3                   # Number of chains to run.
numSavedSteps=10000           # Total number of steps to save per chain.
thinSteps=50                   # Number of steps to "thin" (1=keep every step).
nIter = ceiling( ( (numSavedSteps * thinSteps ) + burnInSteps) / nChains ) # Steps per chain.
t1 = Sys.time()
jagsMod = jags(data = data.jags,
model.file = mod,
n.chains = nChains,
n.adapt = adaptSteps,
n.burnin = burnInSteps,
n.thin = thinSteps,
n.iter = nIter+burnInSteps,
parameters.to.save = params,
parallel = T)
